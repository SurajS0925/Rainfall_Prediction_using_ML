# -*- coding: utf-8 -*-
"""python-sklearn-logistic-regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CZsCvsT7ZfZ2FZaTwVE8oJYDdDNhQpX3
"""

import pandas as pd

train_csv='/content/weatherAUS.csv'

raw_df = pd.read_csv(train_csv)

raw_df

raw_df.info()

raw_df.dropna(subset=['RainToday', 'RainTomorrow'], inplace=True)

!pip install plotly matplotlib seaborn --quiet

# Commented out IPython magic to ensure Python compatibility.
import plotly.express as px
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

sns.set_style('darkgrid')
matplotlib.rcParams['font.size'] = 14
matplotlib.rcParams['figure.figsize'] = (10, 6)
matplotlib.rcParams['figure.facecolor'] = '#00000000'

px.histogram(raw_df, x='Location', title='Location vs. Rainy Days', color='RainToday')

px.histogram(raw_df,
             x='Temp3pm',
             title='Temperature at 3 pm vs. Rain Tomorrow',
             color='RainTomorrow')

px.histogram(raw_df,
             x='RainTomorrow',
             color='RainToday',
             title='Rain Tomorrow vs. Rain Today')

px.scatter(raw_df.sample(2000),
           title='Min Temp. vs Max Temp.',
           x='MinTemp',
           y='MaxTemp',
           color='RainToday')

px.scatter(raw_df.sample(2000),
           title='Temp (3 pm) vs. Humidity (3 pm)',
           x='Temp3pm',
           y='Humidity3pm',
           color='RainTomorrow')

use_sample = False

sample_fraction = 0.1

if use_sample:
    raw_df = raw_df.sample(frac=sample_fraction).copy()

from sklearn.model_selection import train_test_split

train_val_df, test_df = train_test_split(raw_df, test_size=0.2, random_state=42)
train_df, val_df = train_test_split(train_val_df, test_size=0.25, random_state=42)

print('train_df.shape :', train_df.shape)
print('val_df.shape :', val_df.shape)
print('test_df.shape :', test_df.shape)

plt.title('No. of Rows per Year')
sns.countplot(x=pd.to_datetime(raw_df.Date).dt.year);

year = pd.to_datetime(raw_df.Date).dt.year

train_df = raw_df[year < 2015]
val_df = raw_df[year == 2015]
test_df = raw_df[year > 2015]

print('train_df.shape :', train_df.shape)
print('val_df.shape :', val_df.shape)
print('test_df.shape :', test_df.shape)

train_df

val_df

test_df

input_cols = list(train_df.columns)[1:-1]
target_col = 'RainTomorrow'

print(input_cols)

target_col

train_inputs = train_df[input_cols].copy()
train_targets = train_df[target_col].copy()

val_inputs = val_df[input_cols].copy()
val_targets = val_df[target_col].copy()

test_inputs = test_df[input_cols].copy()
test_targets = test_df[target_col].copy()

train_inputs

train_targets

!pip install numpy --quiet

import numpy as np

numeric_cols = train_inputs.select_dtypes(include=np.number).columns.tolist()
categorical_cols = train_inputs.select_dtypes('object').columns.tolist()

train_inputs[numeric_cols].describe()

train_inputs[categorical_cols].nunique()

from sklearn.impute import SimpleImputer

?SimpleImputer

imputer = SimpleImputer(strategy = 'mean')

raw_df[numeric_cols].isna().sum()

train_inputs[numeric_cols].isna().sum()

imputer.fit(raw_df[numeric_cols])

list(imputer.statistics_)

train_inputs[numeric_cols] = imputer.transform(train_inputs[numeric_cols])
val_inputs[numeric_cols] = imputer.transform(val_inputs[numeric_cols])
test_inputs[numeric_cols] = imputer.transform(test_inputs[numeric_cols])

train_inputs[numeric_cols].isna().sum()

raw_df[numeric_cols].describe()

from sklearn.preprocessing import MinMaxScaler

?MinMaxScaler

scaler = MinMaxScaler()

scaler.fit(raw_df[numeric_cols])

print('Minimum:')
list(scaler.data_min_)

print('Maximum:')
list(scaler.data_max_)

train_inputs[numeric_cols] = scaler.transform(train_inputs[numeric_cols])
val_inputs[numeric_cols] = scaler.transform(val_inputs[numeric_cols])
test_inputs[numeric_cols] = scaler.transform(test_inputs[numeric_cols])

train_inputs[numeric_cols].describe()

raw_df[categorical_cols].nunique()

from sklearn.preprocessing import OneHotEncoder

?OneHotEncoder

encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')

encoder.fit(raw_df[categorical_cols])

encoder.categories_

encoded_cols = list(encoder.get_feature_names_out(categorical_cols))
print(encoded_cols)

train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])
val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])
test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])

pd.set_option('display.max_columns', None)

test_inputs

print('train_inputs:', train_inputs.shape)
print('train_targets:', train_targets.shape)
print('val_inputs:', val_inputs.shape)
print('val_targets:', val_targets.shape)
print('test_inputs:', test_inputs.shape)
print('test_targets:', test_targets.shape)

val_inputs

val_targets

from sklearn.linear_model import LogisticRegression

?LogisticRegression

model = LogisticRegression(penalty='l2',solver='newton-cg',max_iter=5000)

model.fit(train_inputs[numeric_cols + encoded_cols], train_targets)

print(numeric_cols + encoded_cols)

print(model.coef_.tolist())

print(model.intercept_)

X_train = train_inputs[numeric_cols + encoded_cols]
X_val = val_inputs[numeric_cols + encoded_cols]
X_test = test_inputs[numeric_cols + encoded_cols]

train_preds = model.predict(X_train)

train_preds

train_targets

train_probs = model.predict_proba(X_train)
train_probs

model.classes_

from sklearn.metrics import accuracy_score

accuracy_score(train_targets, train_preds)

from sklearn.metrics import confusion_matrix

confusion_matrix(train_targets, train_preds, normalize='true')

def predict_and_plot(inputs, targets, name=''):
    preds = model.predict(inputs)

    accuracy = accuracy_score(targets, preds)
    print("Accuracy: {:.2f}%".format(accuracy * 100))

    cf = confusion_matrix(targets, preds, normalize='true')
    plt.figure()
    sns.heatmap(cf, annot=True)
    plt.xlabel('Prediction')
    plt.ylabel('Target')
    plt.title('{} Confusion Matrix'.format(name));

    return preds

train_preds = predict_and_plot(X_train, train_targets, 'Training')

val_preds = predict_and_plot(X_val, val_targets, 'Validatiaon')

test_preds = predict_and_plot(X_test, test_targets, 'Test')

